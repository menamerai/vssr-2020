{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Brazilian House Rent Price\n\nAfter taking a look at the data, I've decided that the houses_to_rentv1 is pretty much unusable for me. So I'll use the v2, and decide to predict the most useful-looking value: Rent amount","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Setup\n\nSetup time. We load all of the necessary libraries and the data.","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%pylab inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the scikit-learn methods and models here\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/brasilian-houses-to-rent/houses_to_rent_v2.csv\").drop([\"total (R$)\"], axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Inference\n\nNow we'll look at the raw data, and use statistical methods and analysis to infer meaning and decide what to visualize, and what to use for the ML process.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_labels = [\"city\", \"area\", \"rooms\", \"bathroom\", \"parking spaces\", \"floor\", \"animal\", \"furniture\", \"hoa (R$)\", \"fire insurance (R$)\", \"property tax (R$)\"]\ndata.dropna()\nX = data[X_labels]\ny = data[\"rent amount (R$)\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.groupby([\"city\"]).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n> Because this dataset seems pretty much impossible to pin down when simply looking at the raw data, I concluse that this would be a great dataset to train on, and would be of use in real life. \n\nAnd thus, we move to the visualization part for better inference","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Data Visualization\n\nWe begin with general and mass visualization, then move on to more specific cases and pairs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(data.corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hmm... It seems that the homeowner tax and the property tax has little to do with anything else, creating a clear black mark. I'll drop them.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop([\"hoa (R$)\", \"property tax (R$)\"], axis=1)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=data, hue=\"city\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Manipulation\n\nTime to change up the data a bit so the model can better infer from it. First step is to convert every string value to integers.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X[\"city\"].unique())\nprint(X[\"animal\"].unique())\nprint(X[\"furniture\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X[\"floor\"].unique())\n# I checked the other columns. Seems to be all fine","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are 5 unique cities, so it should work ok.\n* Sao Paulo = 1\n* Porto Alegre = 2\n* Rio = 3\n* Campinas = 4\n* Belo Horizonte = 5\n\nThere are also two different values in the animal column and the furniture column, and the \"-\" thing in the floor. I will assume it means no data and drop the columns with it.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run this only once, please\nX[\"city\"] = X[\"city\"].apply(lambda x: 1 if x == \"SÃ£o Paulo\" \n                            else 2 if x == \"Porto Alegre\" \n                            else 3 if x == \"Rio de Janeiro\"\n                            else 4 if x ==\"Campinas\" else 5)\nX[\"animal\"] = X[\"animal\"].apply(lambda x: 1 if x == \"acept\" else 0) # Gosh the hell is acept\nX[\"furniture\"] = X[\"furniture\"].apply(lambda x: 1 if x == \"furnished\" else 0)\nX[\"floor\"] = X[\"floor\"].apply(lambda x: np.nan if x == \"-\" else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"... and all done! Now the fun part.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning\n\nHere we go. I have decided to use RandomForestRegressor as my model, as the XGBoost models are too much work.\nFirst we split the dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2)\nprint(\"There are {} samples in the training set and {} samples in the test set\".format(X_train.shape[0], X_test.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This was the place for gridsearch. Now I no longer needs this because I've got the best parameters via this, and self experimentation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\npipeline = Pipeline(steps=[(\"preprocess\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n                            (\"model\", RandomForestRegressor(random_state=1))])\ngrid_params = {\n    \"model__n_estimators\": [140, 160, 180],\n    \"model__criterion\": [\"mse\"],\n    \"model__bootstrap\": [False],\n    \"model__max_depth\": list(range(5, 21, 5))\n}\ngrid_search = GridSearchCV(estimator=pipeline, param_grid=grid_params, cv=3, verbose=1)\ngrid_search.fit(X_train, y_train)\ngrid_search.best_params_\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean Squared Error Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = Pipeline(steps=[(\"preprocess\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n                            (\"model\", RandomForestRegressor(random_state=1,\n                                                            bootstrap=False, \n                                                            criterion=\"mse\",\n                                                            n_estimators=180,\n                                                            max_depth=7))])\nscores = cross_validate(final_model, X_train, y_train, cv=3, scoring=\"neg_root_mean_squared_error\")\nprint(-scores[\"test_score\"].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mean Absolute Error Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model_mae = Pipeline(steps=[(\"preprocess\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n                            (\"model\", RandomForestRegressor(random_state=1,\n                                                            bootstrap=False, \n                                                            criterion=\"mae\",\n                                                            n_estimators=60,\n                                                            max_depth=16))])\nscores_mae = cross_validate(final_model_mae, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_error\")\nprint(-scores_mae[\"test_score\"].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Mini Model \n\nThis predicts the rent price using fire insurance price, and the location of the place.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model_mae_fire = Pipeline(steps=[(\"preprocess\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n                            (\"model\", RandomForestRegressor(random_state=1,\n                                                            bootstrap=False, \n                                                            criterion=\"mse\",\n                                                            n_estimators=200,\n                                                            max_depth=15))])\nscores_mae_fire = cross_validate(final_model_mae_fire, X_train[[\"fire insurance (R$)\", \"city\"]], y_train, cv=3, scoring=\"neg_root_mean_squared_error\")\nprint(-scores_mae_fire[\"test_score\"].mean())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}